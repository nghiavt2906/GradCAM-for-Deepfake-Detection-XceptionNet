## GradCAM as Black-box Explainability method for Deepfake Detection CNN models (XceptionNet)
### Overview
#### Assignment 1 for COMP-6936 (Advanced Machine Learning)
This repository demonstrates applying Explainable AI method like `Grad-CAM` to a CNN model, `XceptionNet`, for Deepfake Detection task. By employing `Grad-CAM`, it helps to give more insights and justify on how decisions are made by CNN models.

### Pretrained model used:
- `XceptionNet`: the model has been trained on dataset from [Celeb-DF: A Large-scale Challenging Dataset for DeepFake Forensics](https://github.com/yuezunli/celeb-deepfakeforensics), then it was used to predict on new dataset from [Kaggle Deepfake Detection Challenge](https://www.kaggle.com/competitions/deepfake-detection-challenge/data) which it has never seen before. Thus, the results can help to draw conclusion on how well the model can generalize on unseen data.

### Methodology
A pretrained `XceptionNet` model was employed to make predictions on new dataset for Deepfake Detection task and applied with Grad-CAM to explain how the model made decisions based on important parts on images. Below are the following steps for the approach:
1. Load and process videos using `OpenCV` library
2. Crop images with face landmarks using `dlib`
3. Load pretrained `XceptionNet` model. The pretrained weights were loaded from this [Github repository](https://github.com/vikrampande7/deepfake-detection). Some of the code for processing images dataset were also taken from this repo for reference.
4. Run the model to make predictions on the processed images. A video is classified as `REAL` (0) or `FAKE` (1) based on a predefined condition. If the percentage of the frames of that video predicted as `FAKE` (1) is greater than a certain `threshold`, which is a hyperparameter, then it is generated by Deepfake. Otherwise, it is classified as `REAL` or not generated by Deepfake. The `threshold` used in this experiment was set to `0.5`.
5. Generate and analyze evaluation metrics regarding predictions from the pretrained model.
6. `timm-vis` library was used to run Grad-CAM and visualize the results using `matplotlib`.
#### File Description
- `ASM1.ipynb`: contains the code for running model predictions and generating Grad-CAM
### Evaluation Metrics
![brave_M4ZkFoLc21](https://github.com/user-attachments/assets/13df1dae-9fcc-4e2d-bcf0-76881b12ccbf)
![brave_djq8OiwQEO](https://github.com/user-attachments/assets/4372e875-4945-4f97-bae8-bb91be708b08)

### Results from Grad-CAM
![brave_PYy9Z3E85n](https://github.com/user-attachments/assets/6569a453-7022-4e83-9f97-7df3c53ac753)

### References
